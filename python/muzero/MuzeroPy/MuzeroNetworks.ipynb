{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Muzero Parameters\n",
    "\n",
    "* 800 simulations per move to pick an action\n",
    "* During the generation of experience in the board game domains, the same exploration scheme as the one described in AlphaZero.\n",
    "\n",
    "* Actions are encoded spatially in planes of the same resolution as the hidden state.\n",
    "\n",
    "## Network Architecture\n",
    "\n",
    "* prediction function uses the same architecture as alphazero, one or two convolutional layers that preserve the resolution but reduce the number of planes, followed by a fully connected layers to the size of the output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(nn.Module):\n",
    "    def __init__(self, filters0, filters1, kernel_size, bn=False):\n",
    "        super().__init__()\n",
    "        blocks = [nn.Conv2d(filters0, filters1, kernel_size, stride=1, padding=kernel_size//2, bias=False)]\n",
    "        if bn:\n",
    "            blocks.append(nn.BatchNorm2d(filters1))\n",
    "        self.conv = nn.Sequential(*blocks)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.conv(x)\n",
    "        return h\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, filters):\n",
    "        super().__init__()\n",
    "        blocks = [Conv(filters, filters, 3, True),\n",
    "                  nn.ReLU(),\n",
    "                  Conv(filters, filters, 3, True)]\n",
    "        self.conv = nn.Sequential(*blocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return nn.ReLU()(x + (self.conv(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ResidualBlock(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10,12,64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = res(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 12, 64, 64])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(x.detach().numpy() == y.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Representation(nn.Module):\n",
    "    '''\n",
    "    Convert observation into hidden abstract state\n",
    "    '''\n",
    "    def __init__(self, input_shape,num_filters,n_res_blocks):\n",
    "        super().__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.board_size = self.input_shape[1] * self.input_shape[2]\n",
    "        blocks = [Conv(self.input_shape[0], num_filters, 3, bn=True),\n",
    "                 nn.ReLU()]\n",
    "        for i in range(n_res_blocks):\n",
    "            blocks.append(ResidualBlock(num_filters))\n",
    "        self.layers = nn.Sequential(*blocks)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "    def inference(self, x):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            rp = self(torch.from_numpy(x).unsqueeze(0))\n",
    "        return rp.cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction(nn.Module):\n",
    "    '''\n",
    "    Dual Network\n",
    "    Policy and value prediction from hidden abstract state\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 input_shape,\n",
    "                 num_filters,\n",
    "                 policy_size=10,\n",
    "                 n_res_blocks=2):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.board_size = self.input_shape[1] * self.input_shape[2]\n",
    "        \n",
    "        # Main convloutional block\n",
    "        blocks = [Conv(self.input_shape[0], num_filters, 3, bn=True),nn.ReLU()]        \n",
    "        for i in range(n_res_blocks):\n",
    "            blocks.append(ResidualBlock(num_filters))\n",
    "        blocks.append(nn.AvgPool2d(kernel_size=self.input_shape[1:]))\n",
    "        self.conv_layers = nn.Sequential(*blocks)\n",
    "        \n",
    "        \n",
    "        # Policy head\n",
    "        self.policy_head = nn.Sequential( nn.Linear(num_filters,policy_size),\n",
    "                                          nn.Softmax() )\n",
    "                      \n",
    "        # Value head\n",
    "        self.value_head  = nn.Sequential( nn.Linear(num_filters,1),\n",
    "                                          nn.Tanh() )\n",
    "                              \n",
    "    def forward(self,s):\n",
    "        h = torch.squeeze(self.conv_layers(s))\n",
    "        return self.policy_head(h), self.value_head(h) \n",
    "#         return h\n",
    "    def inference(self, s):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            p, v = self(torch.from_numpy(s).unsqueeze(0))\n",
    "        return p.cpu().numpy()[0], v.cpu().numpy()[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dynamics(nn.Module):\n",
    "    '''\n",
    "    Transition of hidden abstract state \n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 state_shape,\n",
    "                 act_shape,\n",
    "                 num_filters,\n",
    "                 n_res_blocks=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.state_shape = state_shape\n",
    "        self.act_shape = act_shape\n",
    "        \n",
    "        blocks = [Conv(state_shape[0]+act_shape[0], num_filters, 3, bn=True),\n",
    "                 nn.ReLU()]\n",
    "        for i in range(n_res_blocks):\n",
    "            blocks.append(ResidualBlock(num_filters))\n",
    "        self.layers = nn.Sequential(*blocks)\n",
    "        \n",
    "    def forward(self,s,a):\n",
    "        h = torch.cat([s,a],dim=1)\n",
    "        return self.layers(h)\n",
    "\n",
    "    def inference(self, s, a):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            s = self(torch.from_numpy(s).unsqueeze(0), torch.from_numpy(a).unsqueeze(0))\n",
    "        return s.cpu().numpy()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(33,12,64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = Representation(x.shape[1:],20,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = rep(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33, 20, 64, 64])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyn = Dynamics(s.shape[1:],s.shape[1:],40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_ = dyn(s,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33, 40, 64, 64])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Prediction(s.shape[1:],20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "p,v = pre(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([33, 10]), torch.Size([33, 1]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape,v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generalML",
   "language": "python",
   "name": "genralml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
