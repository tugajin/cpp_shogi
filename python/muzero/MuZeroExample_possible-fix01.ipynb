{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_dkfRUrkjMui"
   },
   "outputs": [],
   "source": [
    "# environment:\n",
    "# pip3 install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vip06874jMul"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1 2 3\n",
      "A _ _ _\n",
      "B O _ _\n",
      "C _ _ _\n",
      "record = B1\n",
      "input feature\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [1. 0. 0.]\n",
      "  [0. 0. 0.]]]\n",
      "input feature\n",
      "[[[1. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 1. 0.]\n",
      "  [0. 1. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "# Implementation of simple game: Tic-Tac-Toe\n",
    "# You can change this to another two-player game.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "BLACK, WHITE =1, -1 # first turn or second turn player\n",
    "\n",
    "class State:\n",
    "    '''Board implementation of Tic-Tac-Toe'''\n",
    "    X, Y = 'ABC',  '123'\n",
    "    C = {0: '_', BLACK: 'O', WHITE: 'X'}\n",
    "\n",
    "    def __init__(self):\n",
    "        self.board = np.zeros((3, 3)) # (x, y)\n",
    "        self.color = 1\n",
    "        self.win_color = 0\n",
    "        self.record = []\n",
    "\n",
    "    def action2str(self, a):\n",
    "        return self.X[a // 3] + self.Y[a % 3]\n",
    "\n",
    "    def str2action(self, s):\n",
    "        return self.X.find(s[0]) * 3 + self.Y.find(s[1])\n",
    "\n",
    "    def record_string(self):\n",
    "        return ' '.join([self.action2str(a) for a in self.record])\n",
    "\n",
    "    def __str__(self):\n",
    "        # output board.\n",
    "        s = '   ' + ' '.join(self.Y) + '\\n'\n",
    "        for i in range(3):\n",
    "            s += self.X[i] + ' ' + ' '.join([self.C[self.board[i, j]] for j in range(3)]) + '\\n'\n",
    "        s += 'record = ' + self.record_string()\n",
    "        return s\n",
    "\n",
    "    def play(self, action):\n",
    "        # state transition function\n",
    "        # action is position inerger (0~8) or string representation of action sequence\n",
    "        if isinstance(action, str):\n",
    "            for astr in action.split():\n",
    "                self.play(self.str2action(astr))\n",
    "            return self\n",
    "\n",
    "        x, y = action // 3, action % 3\n",
    "        self.board[x, y] = self.color\n",
    "\n",
    "        # check whether 3 stones are on the line\n",
    "        if self.board[x, :].sum() == 3 * self.color \\\n",
    "          or self.board[:, y].sum() == 3 * self.color \\\n",
    "          or (x == y and np.diag(self.board, k=0).sum() == 3 * self.color) \\\n",
    "          or (x == 2 - y and np.diag(self.board[::-1,:], k=0).sum() == 3 * self.color):\n",
    "            self.win_color = self.color\n",
    "\n",
    "        self.color = -self.color\n",
    "        self.record.append(action)\n",
    "        return self\n",
    "\n",
    "    def terminal(self):\n",
    "        # terminal state check\n",
    "        return self.win_color != 0 or len(self.record) == 3 * 3\n",
    "\n",
    "    def terminal_reward(self):\n",
    "        # terminal reward \n",
    "        return self.win_color if self.color == BLACK else -self.win_color\n",
    "\n",
    "    def legal_actions(self):\n",
    "        # list of legal actions on each state\n",
    "        return [a for a in range(3 * 3) if self.board[a // 3, a % 3] == 0]\n",
    "\n",
    "    def feature(self):\n",
    "        # input tensor for neural nets (state)\n",
    "        return np.stack([self.board == self.color, self.board == -self.color]).astype(np.float32)\n",
    "\n",
    "    def action_feature(self, action):\n",
    "        # input tensor for neural nets (action)\n",
    "        a = np.zeros((1, 3, 3), dtype=np.float32)\n",
    "        a[0, action // 3, action % 3] = 1\n",
    "        return a\n",
    "\n",
    "state = State().play('B1')\n",
    "print(state)\n",
    "print('input feature')\n",
    "print(state.feature())\n",
    "state = State().play('B2 A1 C2')\n",
    "print('input feature')\n",
    "print(state.feature())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F72fNyxSjMup"
   },
   "outputs": [],
   "source": [
    "# Neural nets with PyTorch\n",
    "# small version of nets used in MuZero paper\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Conv(nn.Module):\n",
    "    def __init__(self, filters0, filters1, kernel_size, bn=False):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(filters0, filters1, kernel_size, stride=1, padding=kernel_size//2, bias=False)\n",
    "        self.bn = None\n",
    "        if bn:\n",
    "            self.bn = nn.BatchNorm2d(filters1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            h = self.bn(h)\n",
    "        return h\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, filters):\n",
    "        super().__init__()\n",
    "        self.conv = Conv(filters, filters, 3, True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.relu(x + (self.conv(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BESoEV3sjMus"
   },
   "outputs": [],
   "source": [
    "num_filters = 8\n",
    "num_blocks = 2\n",
    "\n",
    "class Representation(nn.Module):\n",
    "    ''' Conversion from observation to inner abstract state '''\n",
    "    def __init__(self, input_shape):\n",
    "        super().__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.board_size = self.input_shape[1] * self.input_shape[2]\n",
    "\n",
    "        self.layer0 = Conv(self.input_shape[0], num_filters, 3, bn=True)\n",
    "        self.blocks = nn.ModuleList([ResidualBlock(num_filters) for _ in range(num_blocks)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.layer0(x))\n",
    "        for block in self.blocks:\n",
    "            h = block(h)\n",
    "        return h\n",
    "\n",
    "    def inference(self, x):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            rp = self(torch.from_numpy(x).unsqueeze(0))\n",
    "        return rp.cpu().numpy()[0]\n",
    "\n",
    "class Prediction(nn.Module):\n",
    "    ''' Policy and value prediction from inner abstract state '''\n",
    "    def __init__(self, action_shape):\n",
    "        super().__init__()\n",
    "        self.board_size = np.prod(action_shape[1:])\n",
    "        self.action_size = action_shape[0] * self.board_size\n",
    "\n",
    "        self.conv_p1 = Conv(num_filters, 4, 1, bn=True)\n",
    "        self.conv_p2 = Conv(4, 1, 1)\n",
    "\n",
    "        self.conv_v = Conv(num_filters, 4, 1, bn=True)\n",
    "        self.fc_v = nn.Linear(self.board_size * 4, 1, bias=False)\n",
    "\n",
    "    def forward(self, rp):\n",
    "        h_p = F.relu(self.conv_p1(rp))\n",
    "        h_p = self.conv_p2(h_p).view(-1, self.action_size)\n",
    "\n",
    "        h_v = F.relu(self.conv_v(rp))\n",
    "        h_v = self.fc_v(h_v.view(-1, self.board_size * 4))\n",
    "\n",
    "        # range of value is -1 ~ 1\n",
    "        return F.softmax(h_p, dim=-1), torch.tanh(h_v)\n",
    "\n",
    "    def inference(self, rp):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            p, v = self(torch.from_numpy(rp).unsqueeze(0))\n",
    "        return p.cpu().numpy()[0], v.cpu().numpy()[0][0]\n",
    "\n",
    "class Dynamics(nn.Module):\n",
    "    '''Abstruct state transition'''\n",
    "    def __init__(self, rp_shape, act_shape):\n",
    "        super().__init__()\n",
    "        self.rp_shape = rp_shape\n",
    "        self.layer0 = Conv(rp_shape[0] + act_shape[0], num_filters, 3, bn=True)\n",
    "        self.blocks = nn.ModuleList([ResidualBlock(num_filters) for _ in range(num_blocks)])\n",
    "\n",
    "    def forward(self, rp, a):\n",
    "        h = torch.cat([rp, a], dim=1)\n",
    "        h = self.layer0(h)\n",
    "        for block in self.blocks:\n",
    "            h = block(h)\n",
    "        return h\n",
    "\n",
    "    def inference(self, rp, a):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            rp = self(torch.from_numpy(rp).unsqueeze(0), torch.from_numpy(a).unsqueeze(0))\n",
    "        return rp.cpu().numpy()[0]\n",
    "\n",
    "class Nets(nn.Module):\n",
    "    '''Whole nets'''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        state = State()\n",
    "        input_shape = state.feature().shape\n",
    "        action_shape = state.action_feature(0).shape\n",
    "        rp_shape = (num_filters, *input_shape[1:])\n",
    "\n",
    "        self.representation = Representation(input_shape)\n",
    "        self.prediction = Prediction(action_shape)\n",
    "        self.dynamics = Dynamics(rp_shape, action_shape)\n",
    "\n",
    "    def predict_all(self, state0, path):\n",
    "        '''Predict p and v from original state and path'''\n",
    "        outputs = []\n",
    "        self.eval()\n",
    "        x = torch.from_numpy(state0.feature()).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            rp = self.representation(x)\n",
    "            outputs.append(self.prediction(rp))\n",
    "            for action in path:\n",
    "                a = state0.action_feature(action).unsqueeze(0)\n",
    "                rp = self.dynamics(rp, a)\n",
    "                outputs.append(self.prediction(rp))\n",
    "        #  return as numpy arrays\n",
    "        return [(p.cpu().numpy()[0], v.cpu().numpy()[0][0]) for p, v in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j3DEJPlKjMuu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1 2 3\n",
      "A _ _ _\n",
      "B _ _ _\n",
      "C _ _ _\n",
      "record = \n",
      "p = \n",
      "[[[111 111 111]\n",
      "  [111 111 111]\n",
      "  [111 111 111]]]\n",
      "v =  0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def show_net(nets, state):\n",
    "    '''Display policy (p) and value (v)'''\n",
    "    print(state)\n",
    "    p, v = nets.predict_all(state, [])[-1]\n",
    "    print('p = ')\n",
    "    print((p *1000).astype(int).reshape((-1, *nets.representation.input_shape[1:3])))\n",
    "    print('v = ', v)\n",
    "    print()\n",
    "\n",
    "#  Outputs before training\n",
    "show_net(Nets(), State())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7BlFWmLljMux"
   },
   "outputs": [],
   "source": [
    "# Implementation of Monte Carlo Tree Search\n",
    "\n",
    "class Node:\n",
    "    '''Search result of one abstruct (or root) state'''\n",
    "    def __init__(self, p, v):\n",
    "        self.p, self.v = p, v\n",
    "        self.n, self.q_sum = np.zeros_like(p), np.zeros_like(p)\n",
    "        self.n_all, self.q_sum_all = 1, v / 2 # prior\n",
    "\n",
    "    def update(self, action, q_new):\n",
    "        # Update\n",
    "        self.n[action] += 1\n",
    "        self.q_sum[action] += q_new\n",
    "\n",
    "        # Update overall stats\n",
    "        self.n_all += 1\n",
    "        self.q_sum_all += q_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hz9cn3j6jMuz"
   },
   "outputs": [],
   "source": [
    "import time, copy\n",
    "\n",
    "class Tree:\n",
    "    '''Monte Carlo Tree'''\n",
    "    def __init__(self, nets):\n",
    "        self.nets = nets\n",
    "        self.nodes = {}\n",
    "\n",
    "    def search(self, state, path, rp, depth):\n",
    "        # Return predicted value from new state\n",
    "        key = state.record_string() #どこにノードを保存するかキーを作成。\n",
    "        if len(path) > 0:\n",
    "            key += '|' + ' '.join(map(state.action2str, path))\n",
    "        if key not in self.nodes:\n",
    "            p, v = self.nets.prediction.inference(rp)\n",
    "            self.nodes[key] = Node(p, v)\n",
    "            return v\n",
    "\n",
    "        # State transition by an action selected from bandit\n",
    "        node = self.nodes[key]\n",
    "        p = node.p\n",
    "        mask = np.zeros_like(p)\n",
    "        if depth == 0:\n",
    "            # Add noise to policy on the root node\n",
    "            p = 0.75 * p + 0.25 * np.random.dirichlet([0.15] * len(p))\n",
    "            # On the root node, we choose action only from legal actions\n",
    "            mask[state.legal_actions()] = 1\n",
    "            p *= mask\n",
    "            p /= p.sum() + 1e-16\n",
    "\n",
    "        n, q_sum = 1 + node.n, node.q_sum_all / node.n_all + node.q_sum\n",
    "        ucb = q_sum / n + 2.0 * np.sqrt(node.n_all) * p / n + mask * 4 # PUCB formula\n",
    "        best_action = np.argmax(ucb)\n",
    "\n",
    "        # Search next state by recursively calling this function\n",
    "#         representation = self.nets.dynamics.inference(rp, state.action_feature(best_action))\n",
    "        rp = self.nets.dynamics.inference(rp, state.action_feature(best_action))\n",
    "        \n",
    "        '''\n",
    "        rp not representation????\n",
    "        it could be self.nets.representation \n",
    "        '''\n",
    "        path.append(best_action)\n",
    "        q_new = -self.search(state, path, rp, depth + 1) # With the assumption of changing player by turn\n",
    "        # 自分の関数を呼ぶことでループする。\n",
    "        # best move tree section\n",
    "        node.update(best_action, q_new)\n",
    "\n",
    "        return q_new\n",
    "\n",
    "    def think(self, state, num_simulations, temperature = 0, show=False):\n",
    "        # End point of MCTS\n",
    "        if show:\n",
    "            print(state)\n",
    "        start, prev_time = time.time(), 0\n",
    "        for _ in range(num_simulations):\n",
    "            self.search(state, [], self.nets.representation.inference(state.feature()), depth=0)\n",
    "            # ここで木を伸ばす\n",
    "            # Display search result on every second\n",
    "            if show:\n",
    "                tmp_time = time.time() - start\n",
    "                if int(tmp_time) > int(prev_time):\n",
    "                    prev_time = tmp_time\n",
    "                    root, pv = self.nodes[state.record_string()], self.pv(state)\n",
    "                    print('%.2f sec. best %s. q = %.4f. n = %d / %d. pv = %s'\n",
    "                          % (tmp_time, state.action2str(pv[0]), root.q_sum[pv[0]] / root.n[pv[0]],\n",
    "                             root.n[pv[0]], root.n_all, ' '.join([state.action2str(a) for a in pv])))\n",
    "\n",
    "        #  Return probability distribution weighted by the number of simulations\n",
    "        n = root = self.nodes[state.record_string()].n + 1\n",
    "        n = (n / np.max(n)) ** (1 / (temperature + 1e-8))\n",
    "        return n / n.sum()  #next move probability representing good moves\n",
    "\n",
    "    def pv(self, state):\n",
    "        # Return principal variation (action sequence which is considered as the best)\n",
    "        s, pv_seq = copy.deepcopy(state), []\n",
    "        while True:\n",
    "            key = s.record_string()\n",
    "            if key not in self.nodes or self.nodes[key].n.sum() == 0:\n",
    "                break\n",
    "            best_action = sorted([(a, self.nodes[key].n[a]) for a in s.legal_actions()], key=lambda x: -x[1])[0][0]\n",
    "            pv_seq.append(best_action)\n",
    "            s.play(best_action)\n",
    "        return pv_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LrjwSBIejMu1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1 2 3\n",
      "A _ _ _\n",
      "B _ _ _\n",
      "C _ _ _\n",
      "record = \n",
      "   1 2 3\n",
      "A O O _\n",
      "B _ _ _\n",
      "C X X _\n",
      "record = A1 C1 A2 C2\n",
      "   1 2 3\n",
      "A _ X O\n",
      "B _ O O\n",
      "C X _ _\n",
      "record = B2 A2 A3 C1 B3\n",
      "   1 2 3\n",
      "A _ X O\n",
      "B _ O _\n",
      "C X _ _\n",
      "record = B2 A2 A3 C1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.5, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.5], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search with initialized nets\n",
    "\n",
    "tree = Tree(Nets())\n",
    "tree.think(State(), 100, show=True)\n",
    "\n",
    "tree = Tree(Nets())\n",
    "tree.think(State().play('A1 C1 A2 C2'), 200, show=True)\n",
    "\n",
    "tree = Tree(Nets())\n",
    "tree.think(State().play('B2 A2 A3 C1 B3'), 200, show=True)\n",
    "\n",
    "tree = Tree(Nets())\n",
    "tree.think(State().play('B2 A2 A3 C1'), 200, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C27LMOb4jMu4"
   },
   "outputs": [],
   "source": [
    "# Training of neural nets\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "batch_size = 32\n",
    "num_epochs = 30\n",
    "\n",
    "def gen_target(ep, k):\n",
    "    '''Generate inputs and targets for training'''\n",
    "    # path, reward, observation, action, policy\n",
    "    turn_idx = np.random.randint(len(ep[0]))\n",
    "    ps, vs, ax = [], [], []\n",
    "    for t in range(turn_idx, turn_idx + k + 1):\n",
    "        if t < len(ep[0]):\n",
    "            p = ep[4][t]\n",
    "            a = ep[3][t]\n",
    "        else: # state after finishing game\n",
    "            # p is 0 (loss is 0)\n",
    "            p = np.zeros_like(ep[4][-1])\n",
    "            # random action selection\n",
    "            a = np.zeros(np.prod(ep[3][-1].shape), dtype=np.float32)\n",
    "            a[np.random.randint(len(a))] = 1\n",
    "            a = a.reshape(ep[3][-1].shape)\n",
    "        vs.append([ep[1] if t % 2 == 0 else -ep[1]])\n",
    "        ps.append(p)\n",
    "        ax.append(a)\n",
    "        \n",
    "    return ep[2][turn_idx], ax, ps, vs\n",
    "\n",
    "def train(episodes, nets=Nets()):\n",
    "    '''Train neural nets'''\n",
    "    optimizer = optim.SGD(nets.parameters(), lr=1e-3, weight_decay=1e-4, momentum=0.75)\n",
    "    for epoch in range(num_epochs):\n",
    "        p_loss_sum, v_loss_sum = 0, 0\n",
    "        nets.train()\n",
    "        for i in range(0, len(episodes), batch_size):\n",
    "            k = 4#np.random.randint(4)\n",
    "            x, ax, p_target, v_target = zip(*[gen_target(episodes[np.random.randint(len(episodes))], k) for j in range(batch_size)])\n",
    "            x = torch.from_numpy(np.array(x))\n",
    "            ax = torch.from_numpy(np.array(ax))\n",
    "            p_target = torch.from_numpy(np.array(p_target))\n",
    "            v_target = torch.FloatTensor(np.array(v_target))\n",
    "            \n",
    "            # Change the order of axis as [time step, batch, ...]\n",
    "            ax = torch.transpose(ax, 0, 1)\n",
    "            p_target = torch.transpose(p_target, 0, 1)\n",
    "            v_target = torch.transpose(v_target, 0, 1)\n",
    "\n",
    "            p_loss, v_loss = 0, 0\n",
    "\n",
    "            # Compute losses for k (+ current) steps\n",
    "            for t in range(k + 1):\n",
    "                rp = nets.representation(x) if t == 0 else nets.dynamics(rp, ax[t - 1])\n",
    "                p, v = nets.prediction(rp)\n",
    "                p_loss += torch.sum(-p_target[t] * torch.log(p))\n",
    "                v_loss += torch.sum((v_target[t] - v) ** 2)\n",
    "\n",
    "            p_loss_sum += p_loss.item()\n",
    "            v_loss_sum += v_loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            (p_loss + v_loss).backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] *= 0.85\n",
    "    print('p_loss %f v_loss %f' % (p_loss_sum / len(episodes), v_loss_sum / len(episodes)))\n",
    "    return nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z6FgL4PxjMu6"
   },
   "outputs": [],
   "source": [
    "#  Battle against random agents\n",
    "\n",
    "def vs_random(nets, n=100):\n",
    "    results = {}\n",
    "    for i in range(n):\n",
    "        first_turn = i % 2 == 0\n",
    "        turn = first_turn\n",
    "        state = State()\n",
    "        while not state.terminal():\n",
    "            if turn:\n",
    "                p, _ = nets.predict_all(state, [])[-1]\n",
    "                action = sorted([(a, p[a]) for a in state.legal_actions()], key=lambda x:-x[1])[0][0]\n",
    "            else:\n",
    "                action = np.random.choice(state.legal_actions())\n",
    "            state.play(action)\n",
    "            turn = not turn\n",
    "        r = state.terminal_reward() if turn else -state.terminal_reward()\n",
    "        results[r] = results.get(r, 0) + 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-XpXESW-jMu-",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs_random =  [(-1, 27), (0, 8), (1, 65)]\n",
      "game 0  1  2  3  4  5  6  7  8  9  generated =  [(-1, 1), (0, 1), (1, 8)]\n",
      "p_loss 25.457872 v_loss 4.202150\n",
      "vs_random =  [(-1, 37), (0, 15), (1, 48)] sum =  [(-1, 64), (0, 23), (1, 113)]\n",
      "game 10  11  12  13  14  15  16  17  18  19  generated =  [(-1, 6), (0, 3), (1, 11)]\n",
      "p_loss 14.316779 v_loss 4.284777\n",
      "vs_random =  [(-1, 48), (0, 17), (1, 35)] sum =  [(-1, 112), (0, 40), (1, 148)]\n",
      "game 20  21  22  23  24  25  26  27  28  29  generated =  [(-1, 10), (0, 4), (1, 16)]\n",
      "p_loss 8.085314 v_loss 2.027146\n",
      "vs_random =  [(-1, 37), (0, 24), (1, 39)] sum =  [(-1, 149), (0, 64), (1, 187)]\n",
      "game 30  31  32  33  34  35  36  37  38  39  generated =  [(-1, 12), (0, 5), (1, 23)]\n",
      "p_loss 11.550023 v_loss 2.593464\n",
      "vs_random =  [(-1, 38), (0, 18), (1, 44)] sum =  [(-1, 187), (0, 82), (1, 231)]\n",
      "game 40  41  42  43  44  45  46  47  48  49  generated =  [(-1, 16), (0, 7), (1, 27)]\n",
      "p_loss 8.847354 v_loss 2.181366\n",
      "vs_random =  [(-1, 40), (0, 18), (1, 42)] sum =  [(-1, 227), (0, 100), (1, 273)]\n",
      "game 50  51  52  53  54  55  56  57  58  59  generated =  [(-1, 19), (0, 9), (1, 32)]\n",
      "p_loss 7.607825 v_loss 2.577383\n",
      "vs_random =  [(-1, 47), (0, 10), (1, 43)] sum =  [(-1, 274), (0, 110), (1, 316)]\n",
      "game 60  61  62  63  64  65  66  67  68  69  generated =  [(-1, 20), (0, 12), (1, 38)]\n",
      "p_loss 7.293354 v_loss 2.784195\n",
      "vs_random =  [(-1, 47), (0, 11), (1, 42)] sum =  [(-1, 321), (0, 121), (1, 358)]\n",
      "game 70  71  72  73  74  75  76  77  78  79  generated =  [(-1, 21), (0, 16), (1, 43)]\n",
      "p_loss 6.657523 v_loss 2.445195\n",
      "vs_random =  [(-1, 34), (0, 12), (1, 54)] sum =  [(-1, 355), (0, 133), (1, 412)]\n",
      "game 80  81  82  83  84  85  86  87  88  89  generated =  [(-1, 24), (0, 19), (1, 47)]\n",
      "p_loss 5.287428 v_loss 2.143497\n",
      "vs_random =  [(-1, 40), (0, 7), (1, 53)] sum =  [(-1, 395), (0, 140), (1, 465)]\n",
      "game 90  91  92  93  94  95  96  97  98  99  generated =  [(-1, 28), (0, 20), (1, 52)]\n",
      "p_loss 6.502078 v_loss 2.509936\n",
      "vs_random =  [(-1, 30), (0, 19), (1, 51)] sum =  [(-1, 425), (0, 159), (1, 516)]\n",
      "game 100  101  102  103  104  105  106  107  108  109  generated =  [(-1, 28), (0, 22), (1, 60)]\n",
      "p_loss 6.375321 v_loss 2.553360\n",
      "vs_random =  [(-1, 33), (0, 14), (1, 53)] sum =  [(-1, 458), (0, 173), (1, 569)]\n",
      "game 110  111  112  113  114  115  116  117  118  119  generated =  [(-1, 31), (0, 25), (1, 64)]\n",
      "p_loss 5.903567 v_loss 2.031564\n",
      "vs_random =  [(-1, 28), (0, 14), (1, 58)] sum =  [(-1, 486), (0, 187), (1, 627)]\n",
      "game 120  121  122  123  124  125  126  127  128  129  generated =  [(-1, 33), (0, 30), (1, 67)]\n",
      "p_loss 6.014759 v_loss 2.096743\n",
      "vs_random =  [(-1, 32), (0, 13), (1, 55)] sum =  [(-1, 518), (0, 200), (1, 682)]\n",
      "game 130  131  132  133  134  135  136  137  138  139  generated =  [(-1, 35), (0, 32), (1, 73)]\n",
      "p_loss 5.465238 v_loss 1.929207\n",
      "vs_random =  [(-1, 31), (0, 14), (1, 55)] sum =  [(-1, 549), (0, 214), (1, 737)]\n",
      "game 140  141  142  143  144  145  146  147  148  149  generated =  [(-1, 37), (0, 34), (1, 79)]\n",
      "p_loss 5.290245 v_loss 1.962059\n",
      "vs_random =  [(-1, 31), (0, 12), (1, 57)] sum =  [(-1, 580), (0, 226), (1, 794)]\n",
      "game 150  151  152  153  154  155  156  157  158  159  generated =  [(-1, 39), (0, 36), (1, 85)]\n",
      "p_loss 4.916510 v_loss 1.722544\n",
      "vs_random =  [(-1, 38), (0, 13), (1, 49)] sum =  [(-1, 618), (0, 239), (1, 843)]\n",
      "game 160  161  162  163  164  165  166  167  168  169  generated =  [(-1, 40), (0, 36), (1, 94)]\n",
      "p_loss 5.860532 v_loss 1.604740\n",
      "vs_random =  [(-1, 28), (0, 13), (1, 59)] sum =  [(-1, 646), (0, 252), (1, 902)]\n",
      "game 170  171  172  173  174  175  176  177  178  179  generated =  [(-1, 42), (0, 37), (1, 101)]\n",
      "p_loss 5.176069 v_loss 1.551434\n",
      "vs_random =  [(-1, 27), (0, 12), (1, 61)] sum =  [(-1, 673), (0, 264), (1, 963)]\n",
      "game 180  181  182  183  184  185  186  187  188  189  generated =  [(-1, 43), (0, 38), (1, 109)]\n",
      "p_loss 5.029941 v_loss 1.319070\n",
      "vs_random =  [(-1, 31), (0, 9), (1, 60)] sum =  [(-1, 704), (0, 273), (1, 1023)]\n",
      "game 190  191  192  193  194  195  196  197  198  199  generated =  [(-1, 44), (0, 39), (1, 117)]\n",
      "p_loss 5.040220 v_loss 1.603833\n",
      "vs_random =  [(-1, 27), (0, 7), (1, 66)] sum =  [(-1, 731), (0, 280), (1, 1089)]\n",
      "game 200  201  202  203  204  205  206  207  208  209  generated =  [(-1, 46), (0, 40), (1, 124)]\n",
      "p_loss 4.862252 v_loss 1.818806\n",
      "vs_random =  [(-1, 21), (0, 21), (1, 58)] sum =  [(-1, 752), (0, 301), (1, 1147)]\n",
      "game 210  211  212  213  214  215  216  217  218  219  generated =  [(-1, 48), (0, 42), (1, 130)]\n",
      "p_loss 4.792782 v_loss 1.328434\n",
      "vs_random =  [(-1, 32), (0, 11), (1, 57)] sum =  [(-1, 784), (0, 312), (1, 1204)]\n",
      "game 220  221  222  223  224  225  226  227  228  229  generated =  [(-1, 50), (0, 44), (1, 136)]\n",
      "p_loss 5.212400 v_loss 1.486740\n",
      "vs_random =  [(-1, 23), (0, 13), (1, 64)] sum =  [(-1, 807), (0, 325), (1, 1268)]\n",
      "game 230  231  232  233  234  235  236  237  238  239  generated =  [(-1, 51), (0, 46), (1, 143)]\n",
      "p_loss 4.970729 v_loss 1.583582\n",
      "vs_random =  [(-1, 22), (0, 10), (1, 68)] sum =  [(-1, 829), (0, 335), (1, 1336)]\n",
      "game 240  241  242  243  244  245  246  247  248  249  generated =  [(-1, 53), (0, 48), (1, 149)]\n",
      "p_loss 4.790876 v_loss 1.861980\n",
      "vs_random =  [(-1, 31), (0, 8), (1, 61)] sum =  [(-1, 860), (0, 343), (1, 1397)]\n",
      "game 250  251  252  253  254  255  256  257  258  259  generated =  [(-1, 57), (0, 49), (1, 154)]\n",
      "p_loss 5.328061 v_loss 1.882515\n",
      "vs_random =  [(-1, 24), (0, 7), (1, 69)] sum =  [(-1, 884), (0, 350), (1, 1466)]\n",
      "game 260  261  262  263  264  265  266  267  268  269  generated =  [(-1, 59), (0, 50), (1, 161)]\n",
      "p_loss 5.140548 v_loss 1.738523\n",
      "vs_random =  [(-1, 31), (0, 12), (1, 57)] sum =  [(-1, 915), (0, 362), (1, 1523)]\n",
      "game 270  271  272  273  274  275  276  277  278  279  generated =  [(-1, 64), (0, 51), (1, 165)]\n",
      "p_loss 4.959324 v_loss 1.710389\n",
      "vs_random =  [(-1, 27), (0, 11), (1, 62)] sum =  [(-1, 942), (0, 373), (1, 1585)]\n",
      "game 280  281  282  283  284  285  286  287  288  289  generated =  [(-1, 69), (0, 54), (1, 167)]\n",
      "p_loss 4.995750 v_loss 1.519716\n",
      "vs_random =  [(-1, 28), (0, 6), (1, 66)] sum =  [(-1, 970), (0, 379), (1, 1651)]\n",
      "game 290  291  292  293  294  295  296  297  298  299  generated =  [(-1, 73), (0, 55), (1, 172)]\n",
      "p_loss 4.810399 v_loss 1.625609\n",
      "vs_random =  [(-1, 21), (0, 12), (1, 67)] sum =  [(-1, 991), (0, 391), (1, 1718)]\n",
      "game 300  301  302  303  304  305  306  307  308  309  generated =  [(-1, 73), (0, 58), (1, 179)]\n",
      "p_loss 4.580125 v_loss 1.458640\n",
      "vs_random =  [(-1, 29), (0, 15), (1, 56)] sum =  [(-1, 1020), (0, 406), (1, 1774)]\n",
      "game 310  311  312  313  314  315  316  317  318  319  generated =  [(-1, 75), (0, 61), (1, 184)]\n",
      "p_loss 4.911139 v_loss 1.651426\n",
      "vs_random =  [(-1, 27), (0, 9), (1, 64)] sum =  [(-1, 1047), (0, 415), (1, 1838)]\n",
      "game 320  321  322  323  324  325  326  327  328  329  generated =  [(-1, 80), (0, 62), (1, 188)]\n",
      "p_loss 4.494623 v_loss 1.905087\n",
      "vs_random =  [(-1, 32), (0, 10), (1, 58)] sum =  [(-1, 1079), (0, 425), (1, 1896)]\n",
      "game 330  331  332  333  334  335  336  337  338  339  generated =  [(-1, 83), (0, 65), (1, 192)]\n",
      "p_loss 4.922055 v_loss 1.555878\n",
      "vs_random =  [(-1, 25), (0, 15), (1, 60)] sum =  [(-1, 1104), (0, 440), (1, 1956)]\n",
      "game 340  341  342  343  344  345  346  347  348  349  generated =  [(-1, 88), (0, 68), (1, 194)]\n",
      "p_loss 4.493086 v_loss 1.513282\n",
      "vs_random =  [(-1, 30), (0, 15), (1, 55)] sum =  [(-1, 1134), (0, 455), (1, 2011)]\n",
      "game 350  351  352  353  354  355  356  357  358  359  generated =  [(-1, 91), (0, 73), (1, 196)]\n",
      "p_loss 4.595789 v_loss 1.667848\n",
      "vs_random =  [(-1, 28), (0, 14), (1, 58)] sum =  [(-1, 1162), (0, 469), (1, 2069)]\n",
      "game 360  361  362  363  364  365  366  367  368  369  generated =  [(-1, 94), (0, 75), (1, 201)]\n",
      "p_loss 4.543733 v_loss 1.435697\n",
      "vs_random =  [(-1, 35), (0, 13), (1, 52)] sum =  [(-1, 1197), (0, 482), (1, 2121)]\n",
      "game 370  371  372  373  374  375  376  377  378  379  generated =  [(-1, 95), (0, 80), (1, 205)]\n",
      "p_loss 4.421045 v_loss 1.429184\n",
      "vs_random =  [(-1, 28), (0, 11), (1, 61)] sum =  [(-1, 1225), (0, 493), (1, 2182)]\n",
      "game 380  381  382  383  384  385  386  387  388  389  generated =  [(-1, 97), (0, 84), (1, 209)]\n",
      "p_loss 4.761155 v_loss 1.598251\n",
      "vs_random =  [(-1, 29), (0, 11), (1, 60)] sum =  [(-1, 1254), (0, 504), (1, 2242)]\n",
      "game 390  391  392  393  394  395  396  397  398  399  generated =  [(-1, 97), (0, 89), (1, 214)]\n",
      "p_loss 4.752333 v_loss 1.745113\n",
      "vs_random =  [(-1, 26), (0, 12), (1, 62)] sum =  [(-1, 1280), (0, 516), (1, 2304)]\n",
      "game 400  401  402  403  404  405  406  407  408  409  generated =  [(-1, 101), (0, 89), (1, 220)]\n",
      "p_loss 4.683875 v_loss 1.583879\n",
      "vs_random =  [(-1, 37), (0, 13), (1, 50)] sum =  [(-1, 1317), (0, 529), (1, 2354)]\n",
      "game 410  411  412  413  414  415  416  417  418  419  generated =  [(-1, 102), (0, 92), (1, 226)]\n",
      "p_loss 4.667169 v_loss 1.653502\n",
      "vs_random =  [(-1, 25), (0, 13), (1, 62)] sum =  [(-1, 1342), (0, 542), (1, 2416)]\n",
      "game 420  421  422  423  424  425  426  427  428  429  generated =  [(-1, 104), (0, 96), (1, 230)]\n",
      "p_loss 4.589515 v_loss 1.420979\n",
      "vs_random =  [(-1, 33), (0, 13), (1, 54)] sum =  [(-1, 1375), (0, 555), (1, 2470)]\n",
      "game 430  431  432  433  434  435  436  437  438  439  generated =  [(-1, 108), (0, 98), (1, 234)]\n",
      "p_loss 4.466769 v_loss 1.500270\n",
      "vs_random =  [(-1, 22), (0, 13), (1, 65)] sum =  [(-1, 1397), (0, 568), (1, 2535)]\n",
      "game 440  441  442  443  444  445  446  447  448  449  generated =  [(-1, 109), (0, 100), (1, 241)]\n",
      "p_loss 4.672104 v_loss 1.609402\n",
      "vs_random =  [(-1, 33), (0, 13), (1, 54)] sum =  [(-1, 1430), (0, 581), (1, 2589)]\n",
      "game 450  451  452  453  454  455  456  457  458  459  generated =  [(-1, 113), (0, 103), (1, 244)]\n",
      "p_loss 4.463661 v_loss 1.596410\n",
      "vs_random =  [(-1, 35), (0, 14), (1, 51)] sum =  [(-1, 1465), (0, 595), (1, 2640)]\n",
      "game 460  461  462  463  464  465  466  467  468  469  generated =  [(-1, 115), (0, 106), (1, 249)]\n",
      "p_loss 4.514769 v_loss 1.547764\n",
      "vs_random =  [(-1, 32), (0, 13), (1, 55)] sum =  [(-1, 1497), (0, 608), (1, 2695)]\n",
      "game 470  471  472  473  474  475  476  477  478  479  generated =  [(-1, 116), (0, 110), (1, 254)]\n",
      "p_loss 4.296684 v_loss 1.527109\n",
      "vs_random =  [(-1, 28), (0, 17), (1, 55)] sum =  [(-1, 1525), (0, 625), (1, 2750)]\n",
      "game 480  481  482  483  484  485  486  487  488  489  generated =  [(-1, 120), (0, 111), (1, 259)]\n",
      "p_loss 4.539212 v_loss 1.636162\n",
      "vs_random =  [(-1, 27), (0, 15), (1, 58)] sum =  [(-1, 1552), (0, 640), (1, 2808)]\n",
      "game 490  491  492  493  494  495  496  497  498  499  generated =  [(-1, 121), (0, 112), (1, 267)]\n",
      "p_loss 4.616559 v_loss 1.593971\n",
      "vs_random =  [(-1, 26), (0, 15), (1, 59)] sum =  [(-1, 1578), (0, 655), (1, 2867)]\n",
      "game 500  501  502  503  504  505  506  507  508  509  generated =  [(-1, 124), (0, 113), (1, 273)]\n",
      "p_loss 4.121065 v_loss 1.457520\n",
      "vs_random =  [(-1, 33), (0, 13), (1, 54)] sum =  [(-1, 1611), (0, 668), (1, 2921)]\n",
      "game 510  511  512  513  514  515  516  517  518  519  generated =  [(-1, 127), (0, 114), (1, 279)]\n",
      "p_loss 4.536826 v_loss 1.451330\n",
      "vs_random =  [(-1, 27), (0, 18), (1, 55)] sum =  [(-1, 1638), (0, 686), (1, 2976)]\n",
      "game 520  521  522  523  524  525  526  527  528  529  generated =  [(-1, 127), (0, 115), (1, 288)]\n",
      "p_loss 4.727151 v_loss 1.584203\n",
      "vs_random =  [(-1, 29), (0, 11), (1, 60)] sum =  [(-1, 1667), (0, 697), (1, 3036)]\n",
      "game 530  531  532  533  534  535  536  537  538  539  generated =  [(-1, 129), (0, 117), (1, 294)]\n",
      "p_loss 4.384924 v_loss 1.455952\n",
      "vs_random =  [(-1, 37), (0, 16), (1, 47)] sum =  [(-1, 1704), (0, 713), (1, 3083)]\n",
      "game 540  541  542  543  544  545  546  547  548  549  generated =  [(-1, 130), (0, 122), (1, 298)]\n",
      "p_loss 4.321932 v_loss 1.589091\n",
      "vs_random =  [(-1, 31), (0, 12), (1, 57)] sum =  [(-1, 1735), (0, 725), (1, 3140)]\n",
      "game 550  551  552  553  554  555  556  557  558  559  generated =  [(-1, 130), (0, 128), (1, 302)]\n",
      "p_loss 4.364229 v_loss 1.566847\n",
      "vs_random =  [(-1, 28), (0, 12), (1, 60)] sum =  [(-1, 1763), (0, 737), (1, 3200)]\n",
      "game 560  561  562  563  564  565  566  567  568  569  generated =  [(-1, 132), (0, 134), (1, 304)]\n",
      "p_loss 4.205543 v_loss 1.287316\n",
      "vs_random =  [(-1, 33), (0, 16), (1, 51)] sum =  [(-1, 1796), (0, 753), (1, 3251)]\n",
      "game 570  571  572  573  574  575  576  577  578  579  generated =  [(-1, 136), (0, 137), (1, 307)]\n",
      "p_loss 4.494019 v_loss 1.465709\n",
      "vs_random =  [(-1, 27), (0, 18), (1, 55)] sum =  [(-1, 1823), (0, 771), (1, 3306)]\n",
      "game 580  581  582  583  584  585  586  587  588  589  generated =  [(-1, 136), (0, 142), (1, 312)]\n",
      "p_loss 4.215496 v_loss 1.338679\n",
      "vs_random =  [(-1, 37), (0, 6), (1, 57)] sum =  [(-1, 1860), (0, 777), (1, 3363)]\n",
      "game 590  591  592  593  594  595  596  597  598  599  generated =  [(-1, 136), (0, 146), (1, 318)]\n",
      "p_loss 4.118427 v_loss 1.437452\n",
      "vs_random =  [(-1, 19), (0, 20), (1, 61)] sum =  [(-1, 1879), (0, 797), (1, 3424)]\n",
      "game 600  601  602  603  604  605  606  607  608  609  generated =  [(-1, 138), (0, 150), (1, 322)]\n",
      "p_loss 4.236694 v_loss 1.421559\n",
      "vs_random =  [(-1, 22), (0, 18), (1, 60)] sum =  [(-1, 1901), (0, 815), (1, 3484)]\n",
      "game 610  611  612  613  614  615  616  617  618  619  generated =  [(-1, 141), (0, 153), (1, 326)]\n",
      "p_loss 4.402765 v_loss 1.461124\n",
      "vs_random =  [(-1, 23), (0, 16), (1, 61)] sum =  [(-1, 1924), (0, 831), (1, 3545)]\n",
      "game 620  621  622  623  624  625  626  627  628  629  generated =  [(-1, 143), (0, 157), (1, 330)]\n",
      "p_loss 4.363090 v_loss 1.765308\n",
      "vs_random =  [(-1, 25), (0, 13), (1, 62)] sum =  [(-1, 1949), (0, 844), (1, 3607)]\n",
      "game 630  631  632  633  634  635  636  637  638  639  generated =  [(-1, 147), (0, 160), (1, 333)]\n",
      "p_loss 4.184360 v_loss 1.297492\n",
      "vs_random =  [(-1, 29), (0, 20), (1, 51)] sum =  [(-1, 1978), (0, 864), (1, 3658)]\n",
      "game 640  641  642  643  644  645  646  647  648  649  generated =  [(-1, 149), (0, 164), (1, 337)]\n",
      "p_loss 4.026754 v_loss 1.145168\n",
      "vs_random =  [(-1, 24), (0, 15), (1, 61)] sum =  [(-1, 2002), (0, 879), (1, 3719)]\n",
      "game 650  651  652  653  654  655  656  657  658  659  generated =  [(-1, 152), (0, 168), (1, 340)]\n",
      "p_loss 4.081854 v_loss 1.376930\n",
      "vs_random =  [(-1, 27), (0, 17), (1, 56)] sum =  [(-1, 2029), (0, 896), (1, 3775)]\n",
      "game 660  661  662  663  664  665  666  667  668  669  generated =  [(-1, 155), (0, 173), (1, 342)]\n",
      "p_loss 3.897145 v_loss 1.289767\n",
      "vs_random =  [(-1, 35), (0, 12), (1, 53)] sum =  [(-1, 2064), (0, 908), (1, 3828)]\n",
      "game 670  671  672  673  674  675  676  677  678  679  generated =  [(-1, 158), (0, 175), (1, 347)]\n",
      "p_loss 4.338268 v_loss 1.346782\n",
      "vs_random =  [(-1, 28), (0, 19), (1, 53)] sum =  [(-1, 2092), (0, 927), (1, 3881)]\n",
      "game 680  681  682  683  684  685  686  687  688  689  generated =  [(-1, 161), (0, 177), (1, 352)]\n",
      "p_loss 4.081846 v_loss 1.361620\n",
      "vs_random =  [(-1, 28), (0, 20), (1, 52)] sum =  [(-1, 2120), (0, 947), (1, 3933)]\n",
      "game 690  691  692  693  694  695  696  697  698  699  generated =  [(-1, 163), (0, 180), (1, 357)]\n",
      "p_loss 4.167858 v_loss 1.384405\n",
      "vs_random =  [(-1, 27), (0, 13), (1, 60)] sum =  [(-1, 2147), (0, 960), (1, 3993)]\n",
      "game 700  701  702  703  704  705  706  707  708  709  generated =  [(-1, 163), (0, 185), (1, 362)]\n",
      "p_loss 4.212841 v_loss 1.293224\n",
      "vs_random =  [(-1, 19), (0, 11), (1, 70)] sum =  [(-1, 2166), (0, 971), (1, 4063)]\n",
      "game 710  711  712  713  714  715  716  717  718  719  generated =  [(-1, 166), (0, 188), (1, 366)]\n",
      "p_loss 3.996734 v_loss 1.346715\n",
      "vs_random =  [(-1, 23), (0, 23), (1, 54)] sum =  [(-1, 2189), (0, 994), (1, 4117)]\n",
      "game 720  721  722  723  724  725  726  727  728  729  generated =  [(-1, 168), (0, 195), (1, 367)]\n",
      "p_loss 3.977356 v_loss 1.292669\n",
      "vs_random =  [(-1, 27), (0, 17), (1, 56)] sum =  [(-1, 2216), (0, 1011), (1, 4173)]\n",
      "game 730  731  732  733  734  735  736  737  738  739  generated =  [(-1, 170), (0, 200), (1, 370)]\n",
      "p_loss 4.152645 v_loss 1.395366\n",
      "vs_random =  [(-1, 29), (0, 11), (1, 60)] sum =  [(-1, 2245), (0, 1022), (1, 4233)]\n",
      "game 740  741  742  743  744  745  746  747  748  749  generated =  [(-1, 174), (0, 203), (1, 373)]\n",
      "p_loss 4.114395 v_loss 1.332633\n",
      "vs_random =  [(-1, 35), (0, 17), (1, 48)] sum =  [(-1, 2280), (0, 1039), (1, 4281)]\n",
      "game 750  751  752  753  754  755  756  757  758  759  generated =  [(-1, 175), (0, 211), (1, 374)]\n",
      "p_loss 4.009702 v_loss 1.317366\n",
      "vs_random =  [(-1, 22), (0, 22), (1, 56)] sum =  [(-1, 2302), (0, 1061), (1, 4337)]\n",
      "game 760  761  762  763  764  765  766  767  768  769  generated =  [(-1, 175), (0, 217), (1, 378)]\n",
      "p_loss 4.116208 v_loss 1.407941\n",
      "vs_random =  [(-1, 31), (0, 12), (1, 57)] sum =  [(-1, 2333), (0, 1073), (1, 4394)]\n",
      "game 770  771  772  773  774  775  776  777  778  779  generated =  [(-1, 178), (0, 219), (1, 383)]\n",
      "p_loss 3.985973 v_loss 1.281596\n",
      "vs_random =  [(-1, 36), (0, 11), (1, 53)] sum =  [(-1, 2369), (0, 1084), (1, 4447)]\n",
      "game 780  781  782  783  784  785  786  787  788  789  generated =  [(-1, 181), (0, 223), (1, 386)]\n",
      "p_loss 4.012916 v_loss 1.299962\n",
      "vs_random =  [(-1, 20), (0, 20), (1, 60)] sum =  [(-1, 2389), (0, 1104), (1, 4507)]\n",
      "game 790  791  792  793  794  795  796  797  798  799  generated =  [(-1, 184), (0, 225), (1, 391)]\n",
      "p_loss 3.982586 v_loss 1.135631\n",
      "vs_random =  [(-1, 27), (0, 18), (1, 55)] sum =  [(-1, 2416), (0, 1122), (1, 4562)]\n",
      "game 800  801  802  803  804  805  806  807  808  809  generated =  [(-1, 186), (0, 229), (1, 395)]\n",
      "p_loss 3.982427 v_loss 1.265048\n",
      "vs_random =  [(-1, 24), (0, 14), (1, 62)] sum =  [(-1, 2440), (0, 1136), (1, 4624)]\n",
      "game 810  811  812  813  814  815  816  817  818  819  generated =  [(-1, 187), (0, 235), (1, 398)]\n",
      "p_loss 3.969667 v_loss 1.334029\n",
      "vs_random =  [(-1, 28), (0, 24), (1, 48)] sum =  [(-1, 2468), (0, 1160), (1, 4672)]\n",
      "game 820  821  822  823  824  825  826  827  828  829  generated =  [(-1, 189), (0, 239), (1, 402)]\n",
      "p_loss 4.210085 v_loss 1.274069\n",
      "vs_random =  [(-1, 37), (0, 11), (1, 52)] sum =  [(-1, 2505), (0, 1171), (1, 4724)]\n",
      "game 830  831  832  833  834  835  836  837  838  839  generated =  [(-1, 191), (0, 245), (1, 404)]\n",
      "p_loss 4.017213 v_loss 1.352612\n",
      "vs_random =  [(-1, 30), (0, 14), (1, 56)] sum =  [(-1, 2535), (0, 1185), (1, 4780)]\n",
      "game 840  841  842  843  844  845  846  847  848  849  generated =  [(-1, 196), (0, 248), (1, 406)]\n",
      "p_loss 3.921912 v_loss 1.261370\n",
      "vs_random =  [(-1, 22), (0, 14), (1, 64)] sum =  [(-1, 2557), (0, 1199), (1, 4844)]\n",
      "game 850  851  852  853  854  855  856  857  858  859  generated =  [(-1, 197), (0, 253), (1, 410)]\n",
      "p_loss 3.892839 v_loss 1.278267\n",
      "vs_random =  [(-1, 27), (0, 12), (1, 61)] sum =  [(-1, 2584), (0, 1211), (1, 4905)]\n",
      "game 860  861  862  863  864  865  866  867  868  869  generated =  [(-1, 198), (0, 257), (1, 415)]\n",
      "p_loss 3.942511 v_loss 1.189736\n",
      "vs_random =  [(-1, 16), (0, 25), (1, 59)] sum =  [(-1, 2600), (0, 1236), (1, 4964)]\n",
      "game 870  871  872  873  874  875  876  877  878  879  generated =  [(-1, 200), (0, 263), (1, 417)]\n",
      "p_loss 3.837464 v_loss 1.164071\n",
      "vs_random =  [(-1, 25), (0, 9), (1, 66)] sum =  [(-1, 2625), (0, 1245), (1, 5030)]\n",
      "game 880  881  882  883  884  885  886  887  888  889  generated =  [(-1, 202), (0, 265), (1, 423)]\n",
      "p_loss 3.837237 v_loss 1.244692\n",
      "vs_random =  [(-1, 29), (0, 16), (1, 55)] sum =  [(-1, 2654), (0, 1261), (1, 5085)]\n",
      "game 890  891  892  893  894  895  896  897  898  899  generated =  [(-1, 202), (0, 273), (1, 425)]\n",
      "p_loss 3.966525 v_loss 1.330650\n",
      "vs_random =  [(-1, 29), (0, 9), (1, 62)] sum =  [(-1, 2683), (0, 1270), (1, 5147)]\n",
      "game 900  901  902  903  904  905  906  907  908  909  generated =  [(-1, 202), (0, 279), (1, 429)]\n",
      "p_loss 3.914739 v_loss 1.217881\n",
      "vs_random =  [(-1, 28), (0, 12), (1, 60)] sum =  [(-1, 2711), (0, 1282), (1, 5207)]\n",
      "game 910  911  912  913  914  915  916  917  918  919  generated =  [(-1, 204), (0, 283), (1, 433)]\n",
      "p_loss 3.884190 v_loss 1.294993\n",
      "vs_random =  [(-1, 27), (0, 14), (1, 59)] sum =  [(-1, 2738), (0, 1296), (1, 5266)]\n",
      "game 920  921  922  923  924  925  926  927  928  929  generated =  [(-1, 204), (0, 288), (1, 438)]\n",
      "p_loss 4.038509 v_loss 1.269778\n",
      "vs_random =  [(-1, 18), (0, 25), (1, 57)] sum =  [(-1, 2756), (0, 1321), (1, 5323)]\n",
      "game 930  931  932  933  934  935  936  937  938  939  generated =  [(-1, 206), (0, 294), (1, 440)]\n",
      "p_loss 3.766478 v_loss 1.173095\n",
      "vs_random =  [(-1, 12), (0, 9), (1, 79)] sum =  [(-1, 2768), (0, 1330), (1, 5402)]\n",
      "game 940  941  942  943  944  945  946  947  948  949  generated =  [(-1, 208), (0, 301), (1, 441)]\n",
      "p_loss 3.754240 v_loss 1.157963\n",
      "vs_random =  [(-1, 29), (0, 15), (1, 56)] sum =  [(-1, 2797), (0, 1345), (1, 5458)]\n",
      "game 950  951  952  953  954  955  956  957  958  959  generated =  [(-1, 209), (0, 306), (1, 445)]\n",
      "p_loss 3.620843 v_loss 1.074622\n",
      "vs_random =  [(-1, 24), (0, 10), (1, 66)] sum =  [(-1, 2821), (0, 1355), (1, 5524)]\n",
      "game 960  961  962  963  964  965  966  967  968  969  generated =  [(-1, 210), (0, 312), (1, 448)]\n",
      "p_loss 3.818349 v_loss 1.175808\n",
      "vs_random =  [(-1, 29), (0, 10), (1, 61)] sum =  [(-1, 2850), (0, 1365), (1, 5585)]\n",
      "game 970  971  972  973  974  975  976  977  978  979  generated =  [(-1, 211), (0, 317), (1, 452)]\n",
      "p_loss 3.614445 v_loss 1.274439\n",
      "vs_random =  [(-1, 24), (0, 18), (1, 58)] sum =  [(-1, 2874), (0, 1383), (1, 5643)]\n",
      "game 980  981  982  983  984  985  986  987  988  989  generated =  [(-1, 211), (0, 324), (1, 455)]\n",
      "p_loss 3.638183 v_loss 1.179635\n",
      "vs_random =  [(-1, 23), (0, 15), (1, 62)] sum =  [(-1, 2897), (0, 1398), (1, 5705)]\n",
      "game 990  991  992  993  994  995  996  997  998  999  generated =  [(-1, 213), (0, 327), (1, 460)]\n",
      "p_loss 3.818416 v_loss 1.124508\n",
      "vs_random =  [(-1, 22), (0, 15), (1, 63)] sum =  [(-1, 2919), (0, 1413), (1, 5768)]\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "# Main algorithm of MuZero\n",
    "\n",
    "#num_games = 50000\n",
    "num_games = 1000\n",
    "\n",
    "num_train_steps = 10\n",
    "num_simulations = 30\n",
    "\n",
    "nets = Nets()\n",
    "\n",
    "# Display battle results as {-1: lose 0: draw 1: win} (for episode generated for training, 1 means that the first player won)\n",
    "vs_random_sum = vs_random(nets)\n",
    "print('vs_random = ', sorted(vs_random_sum.items()))\n",
    "\n",
    "episodes = []\n",
    "result_distribution = {1:0, 0:0, -1:0}\n",
    "\n",
    "for g in range(num_games):\n",
    "    # Generate one 1 episode\n",
    "    record, p_targets, features, action_features = [], [], [], []\n",
    "    state = State()\n",
    "    temperature = 0.7 # temperature using to make policy targets from search results\n",
    "    while not state.terminal():\n",
    "        tree = Tree(nets)\n",
    "        p_target = tree.think(state, num_simulations, temperature)\n",
    "        # num_simulation = total number of trials \n",
    "        p_targets.append(p_target)\n",
    "        features.append(state.feature())\n",
    "        # Select action with generated distribution, and then make a transition by that action\n",
    "        action = np.random.choice(np.arange(len(p_target)), p=p_target)\n",
    "        action_features.append(state.action_feature(action))\n",
    "        state.play(action) # update physical state\n",
    "        record.append(action)\n",
    "        temperature *= 0.8 # 探索の多様性を下げるために温度を下げる。,exploitation = greedy\n",
    "    # reward seen from the first turn player\n",
    "    reward = state.terminal_reward() * (1 if len(record) % 2 == 0 else -1)\n",
    "    result_distribution[reward] += 1\n",
    "    episodes.append((record, reward, features, action_features, p_targets))\n",
    "    if g % num_train_steps == 0:\n",
    "        print('game ', end='')\n",
    "    print(g, ' ', end='')\n",
    "\n",
    "    # Training of neural nets\n",
    "    if (g + 1) % num_train_steps == 0:\n",
    "        # Show the result distributiuon of generated episodes\n",
    "        print('generated = ', sorted(result_distribution.items()))\n",
    "        nets = train(episodes, nets)\n",
    "        vs_random_once = vs_random(nets)\n",
    "        print('vs_random = ', sorted(vs_random_once.items()), end='')\n",
    "        for r, n in vs_random_once.items():\n",
    "            vs_random_sum[r] += n\n",
    "        print(' sum = ', sorted(vs_random_sum.items()))\n",
    "        #show_net(nets, State())\n",
    "        #show_net(nets, State().play('A1 C1 A2 C2'))\n",
    "        #show_net(nets, State().play('A1 B2 C3 B3 C1'))\n",
    "        #show_net(nets, State().play('B2 A2 A3 C1 B3'))\n",
    "        #show_net(nets, State().play('B2 A2 A3 C1'))\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wfxSo5L0jMvA"
   },
   "outputs": [],
   "source": [
    "# Show outputs from trained nets\n",
    "\n",
    "print('initial state')\n",
    "show_net(nets, State())\n",
    "\n",
    "print('WIN by put')\n",
    "show_net(nets, State().play('A1 C1 A2 C2'))\n",
    "\n",
    "print('LOSE by opponent\\'s double')\n",
    "show_net(nets, State().play('B2 A2 A3 C1 B3'))\n",
    "\n",
    "print('WIN through double')\n",
    "show_net(nets, State().play('B2 A2 A3 C1'))\n",
    "\n",
    "# hard case: putting on A1 will cause double\n",
    "print('strategic WIN by following double')\n",
    "show_net(nets, State().play('B1 A3'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WZ96jAAqjMvD"
   },
   "outputs": [],
   "source": [
    "# Search with trained nets\n",
    "\n",
    "tree = Tree(net)\n",
    "tree.think(State(), 100000, show=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "MuZeroExample.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "generalML",
   "language": "python",
   "name": "generalml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
